\cast{Praktická část}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                             Tvorba tech stacku                                %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\n{1}{Tvorba tech stacku}

Za účelem důkladného testování výkonu a škálovatelnosti mikroslužeb byl vytvořen tech stack, který zahrnuje technologie pro kontejnerizaci, orchestraci, persistenci, komunikaci, monitorování a testování. 

\n{2}{Požadavky na SW}

Aplikace pro svůj účel nezávislého testování výkonu a škálovatelnosti mikroslužeb vyžaduje několik požadavků, které jsou rozděleny na funkční a nefunkční.

\n{3}{Funkční požadavky}

\n{4}{Mikroslužby}

Každá aplikace musí poskytovat rozhraní REST API s healtcheck enpointem pro informování celého systému o svém stavu. Dalším požadavkem je obecná komunikace mezi službami pomocí vybraných protokolů. Aplikace musí být schopna sbírat a vizualizovat data o výkonu a škálovatelnosti mikroslužeb. To zahrnuje sběr a vizualizaci metrik, logů a traces.


\n{4}{Stack}

Aplikační stack jakožto celek musí zahrnovat komunikaci pomocí protokolů HTTP/2 a gRPC. Je nutné aby implementoval publish - subscribe pattern pro komunikaci mezi vybranými službami. Stack musí zprostředkovat přístup a ukládání dat do relační a timeseries databáze. Musí poskytovat nutné rozhraní pro sběr, uchování a vizualizaci metrik a testovacích dat. Stack musí být schopen konfigurovat testovací scénáře, které se mají provést a také je spouštět v manuálním a automatizovaném režimu.

\n{4}{Sběr a vizualizace dat}

Aplikace musí být schopna sbírat a vizualizovat data o výkonu a škálovatelnosti mikroslužeb. To zahrnuje sběr a vizualizaci metrik, protokolů a tras.

\n{4}{Testování scénářů}

Aplikace musí být schopna provádět testování scénářů, které simuluje zátěž na mikroslužby a zjišťuje, jak se chovají za různých podmínek.

\n{4}{Konfigurace aplikace}

Aplikace musí být schopna konfigurovat testovací scénáře, které se mají provést, a způsob, jakým se mají provést.

\n{3}{Nefunkční požadavky}

\n{4}{Výkon}

Implementace aplikace, respektive jejich služeb, musí být schopna zvládnout zátěž, která je na ně kladena. To zahrnuje schopnost zvládnout požadavky na výkon a škálovatelnost.

\n{2}{Požadavky na HW}

Hardware, na kterém bude aplikace provozována, musí výkonnostně dostačovat pro provozování testovacích scénářů a sběr a vizualizaci dat. Týká se to primárně počtu jader, velikosti paměti a rychlosti diskového I/O. Provozované služby mají určitou základní režii, která se musí brát v potaz.

\n{2}{Výběr technlogií}

Součástí tvorby tech stacku je výběr technologií, které budou použity pro implementaci aplikace. Výběr technologií je závislý na požadavcích na aplikaci a HW, na kterém bude aplikace provozována.

\n{3}{Organizace a správa zdrojů}

\n{4}{Git}
Pro správu souborů práce byl zvolen SCM Git. Git je open-source verzovací, který umožňuje vytvářet, spravovat a sdílet soubory. Git je schopný pracovat s větvemi, které umožňují vytvářet paralelní vývojové větve.

\n{4}{Struktura}
Za účelem jednoduché organizace souborů bylo zvoleno řešení monorepozitáře. Monorepozitář je repozitář, který obsahuje veškeré soubory projektu, ale také relevantní dokumentaci, obrázky, podpůrné nástroj a zdrojové soubory diplomové práce. Následující struktura adresářů byla zvolena pro organizaci souborů.

\begin{itemize}
    \item \textbf{Documentation} - adresář obsahující dokumentaci aplikace.
    \item \textbf{Source} - adresář obsahující zdrojové soubory aplikace.
    \item \textbf{Thesis} - adresář obsahující zdrojové soubory textu diplomové práce a práci samotnou ve formátu pdf.
\end{itemize}

\n{4}{GitHub}
Pro zaručení dostupnosti a sdílení veškerých prostředků souvisejících s prací byl vybrán GitHub, jakožto server pro hostování repozitáře. GitHub je open-source platforma pro verzování souborů a projektů. Navíc poskytuje rozšířující možnosti jako je CI/CD, správa dokumentace a další. Repozitář projektu je veden jako veřejný s licencí MIT.

\n{3}{Kontejnerizace a orchestrace}

Základním prvkem nasazení aplikace je kontejnerizace a orchestrace. Kontejnerizace zajišťuje, že aplikace bude spouštěna v izolovaném prostředí, které je nezávislé na hostitelském systému. Orchestrace zajišťuje, že aplikace bude spouštěna na dostupných zdrojích a bude schopna zvládnout zátěž, která je na ni kladena.

Pro kontejnerizaci byla zvolena technologie Docker. Docker je open-source platforma pro kontejnerizaci aplikací, která umožňuje vytvářet, spouštět a spravovat kontejnery.

Pro orchestraci byla vybrána technologie Kubernetes. Kubernetes je open-source platforma pro orchestraci kontejnerů, která umožňuje automatizovat nasazování, škálování a správu aplikací. Kubernetes je schopný pracovat s kontejnery, které jsou vytvořeny pomocí Dockeru.

\n{3}{Konfigurace nasazení}

Pro konfiguraci nasazení byla zvolena technologie Helm. Helm je open-source platforma pro správu balíčků, která umožňuje vytvářet, spravovat a nasazovat balíčky. Helm je schopný pracovat s balíčky, které jsou vytvořeny pomocí Kubernetes.

Definice balíčků je řešena pomocí konfiguračních souborů, které jsou použity již při tvorbě obecného obrazu. V rámci Helm je základním prvkem chart, který obsahuje definici balíčku a šablonu, která je použita pro generování konfigurace.

\n{3}{Persistenční vrstva}

Persistenční vrsta zprostředovává dlouhodobé uchování dat. Z důvodů požadavků na persistenci byly vybrány následující.

\n{4}{Postgres}

Open-source relační databáze, která umožňuje ukládat a spravovat data. Postgres je schopná pracovat s relačními daty, které jsou uloženy v tabulkách. Poskytuje základní klientský balíček pro .NET, který umožňuje komunikaci s databází. Tento balíček je kompatibilní s Native AoT kompilací.

\n{4}{InfluxDB}

Open-source timeseries databáze, která umožňuje ukládat a spravovat časové řady. Využití InfluxDb je pragramtické z důvodu nativní podbory Influxdb napojení z nástroje K6 pro export testovacích dat.

\n{3}{Komunikační metody}

Za účelem analýzy možností komunikace klienta se službami, ale i interní komunikace, bylo vybráno k implementaci hned několik protokolů. 

\n{4}{REST API} V rámci Kestrel serveru každé služby je využit protokol HTTP/1 a komunikace pomocí REST API. Toto rozhraní slouží pro komunikaci klienta se službou a poskytuje data ve formátu JSON.

\n{4}{gRPC} Vybrané služby implementují komunikaci pomocí protokolu HTTP/2 a gRPC. Za tímto účelem mají zmíněné služby otevřené rozhraní na dodatečném portu. gRPC protokol je využit přístupem model first, tedy rozhraní je definováno pomocí protobuf souboru a následně je vygenerován kód pro komunikaci.

\n{4}{RabbitMQ} Pro implementaci komunikace prodle vzoru Publish - Subscribe byl vybrán message broker RabbitMQ. Umožňuje službám odebírat data z jiných služeb a zároveň poskytovat data jiným službám. Tím je zajištěna asynchronní messaging mezi službami.

\n{3}{Monitorovací nástroje}

Pro monitorování aplikace byl zvolen Grafana observability stack pro jeho pokrytí komplexní škály monitorovacích dat. Grafana observability stack zahrnuje nástroje pro sběr, vizualizaci a analýzu dat.

\n{4}{Grafana}

Grafana je open source webová aplikace pro analýzu a interaktivní vizualizaci dat. Poskytuje možnost sestavit dashboard z komponent jako jsou grafy, tabulky a další. Jedná se o velmi populární technologii v doménách serverové infrastruktury a monitorování. Grafana umožňuje sjednotit monitorovací služby a zobrazit data v reálném čase. Podporuje širokou škálu datových zdrojů, jako jsou Prometheus, InfluxDB, Tempo, Loki nebo Elasticsearch, což umožňuje jednoduchou konfiguraci a připojení cílových dat. Kombinací dat z různých zdrojů umožňuje vytvářet komplexní pohled na celý systém. To je obzlvášť cenné pro analýzu systému pomocí kombinací metrických dat.

\n{4}{Prometheus}
 
Open-source monitorovací systém. Shromažďuje a ukládá metriky jako time-series data a umožňuje se na ně dotazovat pomocí vlastního výkonného jazyka PromQL. Prometheus je zvláště vhodný pro monitorování microservice architektur díky své schopnosti automaticky objevovat cíle. Jeho architektura podporuje více modelů získávání dat, stahování metrik z cílových služeb nebo collectorů, odesílání metrik přes gateway a zprostředkování notifikací.

\n{4}{Loki}

Škálovatelný agregátor logů. Na rozdíl od obdobných systémů pro agregaci logů, jenž indexují všechna data, Loki indexuje pouze metadata, přičemž ukládá celá data logu efektivním způsobem. Loki je navržen tak, aby jednoduše spolupracoval s Grafanou a umožňuje rychle vyhledávat a vizualizovat logy.

\n{4}{Tempo}

Je snadno ovladatelný open-source backend pro distribuované sledování požadavků. Tempo podporuje ukládání a načítání traces, které jsou přijímány ze zdrojů jako Jaeger, Zipkin a OpenTelemetry. Na rozdíl od mnoha jiných systémů pro traces nevyžaduje Tempo žadné předem definované schéma. Je navržen tak, aby se bezproblémově integroval s Prometheus a Loki.

\n{4}{OpenTelemetry}

Open source collector telemetrických dat. Poskytuje jednotný, vendor-agnostic způsob sběru, zpracování a exportu telemetrických dat  Je konfigurovatelný a podporuje více pipeline, které mohou upravovat telemetrická data při jejich průchodu. Výrazně zjednodušuje instrumentaci služeb, protože umožňuje agregovat a exportovat metriky, taces a logy do různých analytických a monitorovacích nástrojů. Poskytuje podporu pro export dat do Prometheus, Tempo i Loki.

\n{3}{Testovací nástroje}

\n{4}{K6}

Nástroj pro výkonové testování, který umožňuje vývojářům testovat výkon svých aplikací. K6 umožňuje vývojářům vytvářet a spouštět testy, které simuluji reálné uživatelské scénáře. Tímto je zajištěno, že aplikace je schopna zvládnout požadavky uživatelů. K6 je nástroj, který je možné využít pro testování mikroslužeb, protože umožňuje vývojářům vytvářet testy, které simuluji reálné uživatelské scénáře.

\n{3}{Testovací služby}

Pro implementaci testovacích služeb z podstaty práce zvolena technologie .NET, konkrétně jazyk C\#. Služby budou implementovány jako mikroslužby a budou podporovat kontejnerizované nasazení v microservice architektuře. Služby budou vytvořeny tak, že každou dílčí službu reprezentuje projektový soubor s doménových kódem. Celé řešení spolu s dílčími knihovnami bude součástí jednoho solution souboru.

Pro řešení byla vybrána nejnovější verze .NET SDK 8.0, která poskytuje nejrozsáhlejší impelmentaci a podporu pro nativní AoT kompilaci. Jakožto nástroj pro vývoj a správu projektů byl zvolen JetBrains Rider. Rider je IDE, které poskytuje širokou škálu funkcí pro vývoj aplikací v .NET.

Konkrétní knihovny použité v rámci implementace budou záviset na konkrétních požadavcích na služby a popsány v následující sekci.

\n{2}{Návrh a implementace testovacích služeb}

Následující pasáž se zabírá návrhem a implementací testovacích služeb, které budou využity pro analýzu vývoje a výkonu jednotlivých kompilací AOT a JIT v rámci .NET.

\n{3}{Architektura}

Pro implementaci požadované funkcionality bylo zvoleno následující rozdělení zodpovědnosti služeb:

\begin{itemize}
    \item \textbf{SRS - Signal reading service} - služba, která simuluje čtecí zařízení, které čte data ze zdroje a poskytuje je ostatním službám. Poskytuje REST API rozhraní.
    \item \textbf{FUS - File Upload Service} - služba, která simuluje zapisovací zařízení, zapisuje nebo čte data do persistentního úložiště. Poskytuje REST API a gRPC rozhraní.
    \item \textbf{BPS - Batch Processing Service} - služba, která zpracovává data z jiných služeb. Reaguje na požadavek o hromadném zpracování při předem definovaném splnění podmínek. Poskytuje REST API a gRPC rozhraní. Je přihlášena do RabbitMQ jako subscriber.
    \item \textbf{EPS - Event Publishing Service} - slouží k vyvolání události, která je následně zpracována jinými službami. Poskytuje REST API rozhraní. Je přihlášena do RabbitMQ jako publisher.
\end{itemize}

obrázek architektury

\n{4}{Řešení kompilačních cílů}
Pro kompilaci do nativního AOT kódu byl využit atribut PublishAoT v projektovém souboru. Za účelem zajištění co největší podobnosti služeb zacílených na AOT a JIT kompilaci, bude využito zadefinování konstantních hodnot v rámci projektu. Konstanty \emph{JIT} a \emph{AOT} budou využity pro rozlišení chování služeb v rámci obou kompilačních verzí. S použitím direktiv kompilátoru a zmíněných konstant bude v nutných případech docíleno rozdílného volání API při snaze zachovat totožnou funkcionalitu.

foto využití konstant v kódu

\n{3}{Organizace zdrojových souborů služeb}

Organizace zdrojových souborů služeb, knihoven a pomocných souborů je řešena v rámci hlavního adresáře obsahujícího .NET solution soubor, pomocné soubory a solution složky s konkrétními projekty služeb a knihoven. Následující
stromový graf představuje adresářovou strukturu projektu.
    
\begin{forest}
    for tree={
      font=\ttfamily,
      grow'=0,
      child anchor=west,
      parent anchor=south,
      anchor=west,
      calign=first,
      edge path={
        \noexpand\path [draw, \forestoption{edge}]
        (!u.south west) +(7.5pt,0) |- node[fill,inner sep=1.25pt] {} (.child anchor)\forestoption{edge label};
      },
      before typesetting nodes={
        if n=1
          {insert before={[,phantom]}}
          {}
      },
      fit=band,
      before computing xy={l=15pt},
    }
  [DTA
    [Common
      [DTA.Abstractions]
      [DTA.Extensions.Common]
      [DTA.Extensions.Postgre]
      [DTA.Extensions.Swagger]
      [DTA.Extensions.Telemetry]
      [DTA.Migrator]
      [DTA.Models]
    ]
    [Services
      [DTA.BPS]
      [DTA.EPS]
      [DTA.FUS]
      [DTA.SRS]
    ]
    [SolutionItems
      [Directory.Build.props]
      [NuGet.config]
    ]
    [.gitignore]
    [DTA.sln]
  ]
  \end{forest}


\n{3}{Společná struktura služeb}

Každá z vyvinutých služeb využívá konkrétní .NET SDK \emph{Microsoft.NET.Sdk.Web}, které umožňuje využít WebApplication pro registraci a konfiguraci funkcionality služby a zároveň poskytuje konfigurovatelný Kestrel server. Pro zajištění jednotného přístupu k logování, metrikám a konfiguraci byly vytvořeny společné knihovny, které jsou využity ve všech službách.

\begin{forest}
    for tree={
      font=\ttfamily,
      grow'=0,
      child anchor=west,
      parent anchor=south,
      anchor=west,
      calign=first,
      edge path={
        \noexpand\path [draw, \forestoption{edge}]
        (!u.south west) +(7.5pt,0) |- node[fill,inner sep=1.25pt] {} (.child anchor)\forestoption{edge label};
      },
      before typesetting nodes={
        if n=1
          {insert before={[,phantom]}}
          {}
      },
      fit=band,
      before computing xy={l=15pt},
    }
  [DTA.SampleService
    [Api
      [Rest]
      [Grpc]
      [Rabbit]
    ] 
    [Extensions
      [ProgramExtensions.cs]
    ]
    [Monitoring
      [AppMonitor.cs]
    ]
    [Properties
      [launchSettings.json]
    ]
    [Services
      [Interfaces
        [ISampleService.cs]
      ]
      [SampleService.cs]
    ]
    [apssettings.json]
    [Dockerfile-AOT]
    [Dockerfile-JIT]
    [DTA.SampleService.csproj]
    [Program.cs]
  ]
  \end{forest}


  \begin{itemize}
    \item \textbf{Api} - obsahuje implementaci rozhraní služby
    \item \textbf{Extensions} - implementuje extension metody specifické pro doménu služby
    \item \textbf{Monitoring} - obsahuje statickou třídu, která drží reference na počítadla metrik
    \item \textbf{Service} - ve složce jsou implementovány služby, které provádějí doménovou logiku služby
    \item \textbf{Properties} - drží konfiguraci pro spuštění služby
    \item \textbf{Program.cs} - vstupní bod služby
    \item \textbf{appsettings.json} - konfigurace služby
    \item \textbf{Dockerfile-AOT} - soubor pro tvorbu Docker obrazu pro AOT kompilaci
    \item \textbf{Dockerfile-JIT} - soubor pro tvorbu Docker obrazu pro JIT kompilaci
\end{itemize}

Specifické služby obsahují dodatečné adresáře a soubory nutné pro implementaci jejich doménové funkce.

\n{3}{Knihovny 3. stran}

Pro implementaci funkcionality aplikace byly využity následující knihovny třetích stran.

\n{4}{Npgsql}

Npgsql je open-source ADO.NET provider pro PostgreSQL, který umožňuje komunikaci s PostgreSQL databází. Npgsql poskytuje základní balíček funkcí pro vytvoření připojení na základě standardizovaného řetězce pro připojení. Tento balíček sice není plně kompatibilní s AOT kompilací, funkce které jsou využity v rámci aplikace jsou avšak kompatibilní.

\n{4}{Dapper}

Dapper je open-source ORM knihovna pro .NET, která umožňuje mapovat databázové struktury na C\# objekty a vytvářet a provádět dotazy na databázi. \emph{Dapper.AOT} je dílčí knihovna, která umožňuje vytvářet a provádět dotazy na databázi v rámci AOT kompilace. Toho je zajištěno tím, že Dapper.AOT generuje kód pro dotazy na databázi v době kompilace. Využívá k tomu interceptorů a generátorů. Samotný balíček Dapper.AOT obsahuje další knihovnu - \emph{Dapper.Advisor}, která pomáhá s analýzou zdrojového kódu a generováním kódu pro dotazy na databázi.

\n{4}{OpenTelemetry}

OpenTelemetry zprostředkovává množinu knihoven pro sběr, zpracování a export telemetrických dat. V rámci knihovny je umožňeno registrace vlastních metrik, logů a traces, ale také nastavení exportu vybraných systémových dat sbíraných v rámci knihoven .NET.

\n{4}{Grpc}

Knihovny pro implementaci komunikace pomocí protokolu HTTP/2 a gRPC. Konkrétně jsou využity \emph{Grpc.AspNetCore} v případě serveru, \emph{Grpc.Net.Client} pro klienta a \emph{Google.Protobuf} s \emph{Grpc.Tools} pro generování modelů v přístupu model first.

\n{4}{RabbitMQ}

Komunikace a implementace publish subscribe vzoru je umožněna knihovnou \emph{RabbitMQ.Client}. S její pomocí jsou vytvářeny fronty, dochází k přihlášení k odběru zpráv a jejich publikování.

\n{4}{Swagger}

Grafické rozhraní pro vizualizaci a testování REST API služeb. Swagger je využit pouze v kombinaci konfigurací \emph{JIT Debug}. K tomuto účelou jsou využity knihovny \emph{Swashbuckle.AspNetCore} a \emph{Microsoft.AspNetCore.OpenApi}.

\n{3}{Společné knihovny}

V rámci zjednodušení tvorby služeb, jednotné implementaci a konfiguraci, ale také z důvodu zajištění některé základní ale klíčové funkcionality, byly vytvořeny společné knihovny. Tyto knihovny obsahují společné třídy, rozhraní a konfigurace, které jsou použity ve všech službách.

\n{4}{Persistence}

Pro implementaci persistence byla vytvořena pomocná knihovna \\ \emph{DTA.Extensions.Postgres}, která poskytuje pomocnou funkcionalitu pro zajištění existence databáze pro službu, dle konfigurace v řetězci pro připojení.

\n{4}{Migrace}

Zajištění migrace databáze bylo implementováno po vlastní ose minimalistickým migrátorem v knihovně \emph{DTA.Migrator}. Tato knihovna poskytuje základní funkcionalitu pro vytvoření databáze, vytvoření tabulek a indexů, ale také zajištění migrace dat a verzování změn.

\n{4}{Telemetrie}

Knihovna \emph{DTA.Extensions.Telemetry} zprostředkovává extensions metody pro jednotnou a jednoduchou registraci sběru a export telemetrických dat napříč službami.

\n{4}{Modely}

Knihovna \emph{DTA.Models} obsahuje společné modely, které jsou využity ve službách. Je tím docílena viditelnost na datové struktury rozhraní aplikace napříč všemi službami, jež knihovnu referencují.

\n{4}{Obecná funkcionalita}

Za účelem sjednocení funkcionality využité napříč všemi službami jsou implementovány extension metody v knihovně \emph{DTA.Extensions.Common}. Zde je poskytnuta funkcionalita pro sestavení názvů pro službu.

\n{3}{Společná konfigurace}

Součástí řešení je společná konfigurace, která je využita ve všech službách. Ta je řešena jedna na úrovni solution souboru, tak i Directory.Build.props souboru. Týká se jednotné distribuce projektových atributů pro verzi, kompatibilitu s AOT, vynucení konkrétních pravidel pro kód a analyzéry.

\n{3}{SRS - Signal reading service}

Služba v systému hraje roli čtecího zařízení, které čte data ze zdroje a poskytuje je ostatním službám. Tato služba simulu základní kámen celého systému, značně ovlivňuje výkon a škálovatelnost celého systému. Očekává se velké množství požadavků na tuto službu.

Za účelem zjednodušení implementace není využito čtení dat ze skutečného zdroje, ale jsou generována náhodná data. Načež data jsou následně poskytována se simulovaným zdržením, časově založenému na měření skutečného zdržení systému při čtení dat ze vzdáleného zdroje u obdobného systému. Tato služba je implementována rozhraní jako  které poskytuje data ve formátu JSON. (TODO: Obrázek návrhu architektury a rozhraní služby).

\newline

\begin{apiRoute}{get}{/api/storage/\{id\}}{get specific storage with id}
	
	\begin{routeParameter}
		\routeParamItem{id}{id of storage}
	\end{routeParameter}
	\begin{routeResponse}{application/json}
		\begin{routeResponseItem}{200}{ok}
			\begin{routeResponseItemBody}
{     
	"id": 867654678,
	"name" : "Apfelmus",
	"count" : 25
}
			\end{routeResponseItemBody}
		\end{routeResponseItem}
		\begin{routeResponseItem}{404}{error: storage not found}
			\begin{routeResponseItemBody}
{
	"message": "storage with id '11' not found!"
}
			\end{routeResponseItemBody}
		\end{routeResponseItem}
	\end{routeResponse}
	
\end{apiRoute}


\n{3}{FUS - File Upload Service}

Služba v systému hraje roli zapisovacího zařízení, které zapisuje data do zdroje. Tato služba hraje roli méně vytíženého služby, která nemá značný vliv na fungování systému jako celku. Požadavky, jenž musí vyřídit nejsou kritické a nutné řešit s minimální odezvou.

Služba je implementována s REST API rozhraním. (TODO: Obrázek návrhu architektury a rozhraní služby).

\n{3}{BPS - Batch Processing Service}

Služba v systému hraje roli zpracovávajícího zařízení, které zpracovává data z jiných služeb. Tato služba hraje roli služby, která je závislá na ostatních službách a zpracovává data z nich. Reaguje na požadavek o hromadném zpracování při předem definovaném splnění podmínek.

\n{3}{FRS - Fast Response Service}

Služba v systému hraje roli rychlého zpracovávajícího zařízení, které zpracovává data z jiných služeb. Tato služba hraje roli služby, která je závislá na kritických systémech 3. strany a potřebují v co nejkratším čase odpovídat.

\n{3}{Přehled řešení}

Obrázek adresářové struktury + diagram služeb + popis

\n{2}{Konfigurace aplikace}

\n{3}{Konfigurace služeb}

\n{4}{Nginx}

Pro nginx je dodatečná konfigurace dodána pomocí souboru nginx.conf jenž je namountován do kontejneru. Tento soubor obsahuje konfiguraci pro nginx, která je použita při spuštění kontejneru.

Základní pravidla směrování

\begin{itemize}
    \item / - cesta na statickou hlavní stránku-rozcestník aplikace
    \item /grafana - směrování na Grafanu
    \item /fus - směrování na FUS
    \item /srs - směrování na SRS
    \item /bps - směrování na BPS
    \item /frs - směrování na FRS
\end{itemize}

\n{4}{LGTM - Monitorovací stack}

LGTM jakožto monitorovací stack zároveň konfiguruje veškeré monitorovací nástroje. Značnou část konfigurace představuje propojení nástrojů a tato konfigurace je řešena pomocí konfiguračních souborů, které jsou použity již při tvorbě obecného obrazu.

Dodatečná konfigurace je řešena podle proměnných prostředí a týká se pouze malé množiny nastavení specifickýh pro správný běh monitorovacích nástrojů v celém stacku.

\begin{itemize}
    \item \textbf{GF\_SERVER\_ROOT\_URL} - nastavení URL, na které bude Grafana dostupná. Toto nastavení je důležité pro správné směrování požadavků na Grafanu.
    \item \textbf{GF\_SERVER\_SERVE\_FROM\_SUB\_PATH} - nastavení, které určuje, zda bude Grafana dostupná z podadresáře v URL. Toto nastavení je důležité pro správné směrování požadavků na Grafanu.
    \item \textbf{GF\_AUTH\_ANONYMOUS\_ENABLED} - nastavení, které určuje, zda bude povoleno anonymní přihlášení do Grafany.
\end{itemize}

\n{4}{SGS - Signal Generation Service}

\n{4}{FUS - File Upload Service}

\n{4}{BPS - Batch Processing Service}

\n{4}{FRS - Fast Response Service}

\n{4}{K6}

\n{3}{Nastavení uživatelského rozhraní}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                             Testování scénářů                                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\n{1}{Testování scénářů}

Testování scénářů je klíčovou součástí testování výkonu a škálovatelnosti mikroslužeb. Scénáře jsou definovány jako soubor kroků, které mají být provedeny, a jsou použity k simulaci zátěže na mikroslužby. Scénáře jsou vytvořeny pomocí testovacích nástrojů, které umožňují vytvářet a spouštět testy, které simuluji reálné uživatelské scénáře.

\n{2}{Požadavky na scénáře}

Scénáře musí být vytvořeny tak, aby simulovali reálné uživatelské scénáře. To znamená, že musí být vytvořeny tak, aby obsahovaly kroky, které mají být provedeny, a musí být vytvořeny tak, aby obsahovaly data, která mají být použita.

\n{2}{Popis scénářů}

Následující sekce obsahuje popis scénářů, které byly vytvořeny pro testování výkonu a škálovatelnosti mikroslužeb kompilovaných JIT a AoT. Ke každému scénáři patři odpovídající sada souborů scriptů a konfigurací. Rovněž každý scénář disponuje vlastním interaktivním dashboardem v Grafaně, který umožňuje sledovat výsledky testů v reálném čase.

\n{3}{Scénář 1 - schopnost odpovídat služeb}

Scénář 1 je zaměřen na schopnost mikroslužeb odpovídat na požadavky. K tomuto účelu je využit základní endpoint \emph{/health}, který informuje o stavu služby. Scénář je vytvořen tak, aby simuloval zátěž na mikroslužby a zjišťoval, zda jsou schopny odpovídat na požadavky.

Jelikož healthcheck endpoint je triviální ve své implementaci, nehraje roli další režie spojená se zpracováním logiky požadavku. Tímto je zajištěno, že se otestuje maximální vliv jednotlivých nasazení na výkon a škálovatelnost mikroslužeb.

\n{3}{Scénář 2 - přístup k persistenci}

Cílem tohoto scénáře je otestovat schopnost poradit si s vysokým množství asynchroních operací přístupu k datům. Scénař testuje schopnost mikroslužeb zpracovávat požadavky na zápis a čtení dat z databáze.


\n{3}{Scénář 3 - zátěž zpracování dat}

Cílem tohoto scénáře je otestovat schopnost mikroslužeb v jednotlivých architekturách zpracovat náročnější operace. Scénář se zaměřuje na samotnou podstatu přístupu k vnitřnímu systémového API, efektivitě jeho využití a další režii, která by mohla být odlišná mezi JIT a AoT kompilací.

\n{3}{Scénář 4 - komunikace mezi službami}

Tento scénář je zaměřen na schopnost a výkkonosti mikroslužeb při komunikaci mezi sebou. Toho je docíleno využitím různých komunikačních protokolů, kdy je otestována komunikace:

\begin{itemize}
    \item \textbf{REST} - přes http1
    \item \textbf{gRPC} - přes http2
    \item \textbf{PubSub} - přes message broker
\end{itemize}

\n{3}{Scénář 5 - rychlost spuštění služby}

Cílem tohoto scénáře je otestovat rychlost spuštění služby. Scénář testuje, jak rychle je služba schopna odpovědět na požadavek po spuštění. V rámci testu jsou testovány různé endpointy, které jsou volány po spuštění služby.

\n{2}{Zpracování a vizualizace dat}

Po provedení testování scénářů je nutné zpracovat a vizualizovat data, která byla získána. To zahrnuje zpracování dat, která byla získána z testování scénářů, a zpracování dat, která byla získána z monitorovacích nástrojů.

\n{3}{Monitorování v reálném čase}

Monitorování v reálném čase je klíčovou součástí testování výkonu a škálovatelnosti mikroslužeb. Monitorování v reálném čase umožňuje sledovat výkon a škálovatelnost mikroslužeb při běhu testů.

Toho je docíleno využitím dashboardů v grafaně, důkladnou konfigurací a zobrazením metrik, kterých sběr je implementován v rámci mikroslužeb.

Dalším aspektem monitorování v reálném čase je zobrazení výsledků testů v reálném čase. Toho je rovněž docíleno pomocí specifických dashboardů v Grafaně, které integrují data z K6 testovacího nástroje a zaslané do InfluxDb. Díky propojení Grafany s InfluxDb je možné sledovat výsledky testů v reálném čase.

\n{3}{Sběr historických dat}

Historická data jsou automaticky ukládána do jednotlivých databází při sběru. Po propagaci telemetrických dat do jednotného collectoru OpenTelemetry jsou data dále poskytována službám Loki, Tempo a Prometheus. Ty jedna jednotlivá telemetrická data zpracují, zároveň ale slouží jako jejich persistence. Data z výsledků testů jsou ukládána do InfluxDb.

% \n{2}{Obrázek}
% Obrázek \ref{fig:logo} prezentuje logo Fakulty aplikované informatiky.

% % Obrázek lze vkládat pomocí následujícího zjednodušeného stylu, nebo klasickým LaTex způsobem
% % Pozor! Obrázek nesmí obsahovat alfa kanál (průhlednost). Jde to totiž proti požadovanému standardu PDF/A.
% \obr{Popisek obrázku}{fig:logo}{0.5}{graphics/logo/fai_logo_cz.png}


% \n{2}{Tabulka}
% Tabulka \ref{tab:priklad} obsahuje dva řádky a celkem 7 sloupců.

% % Tabulku lze vkládat pomocí následujícího zjednodušeného stylu, nebo klasickým LaTex způsobem
% \tab{Popisek tabulky}{tab:priklad}{0.65}{|l|c|c|c|c|c|r|}{
%   \hline
%    & 1 & 2 & 3 & 4 & 5 & Cena [Kč] \\ \hline
%   \emph{F} & (jedna) & (dva) & (tři) & (čtyři) & (pět) & 300 \\ \hline
% }


% \n{2}{Citování}
% Následuje ukázka odkazování na různé zdroje:
% \begin{itemize}
% 	\item kniha \cite{HRW1997},
% 	\item kapitola v knize \cite{Delorme2006},
% 	\item článek v odborném žurnálu \cite{Bourreau2006},
% 	\item konferenční příspěvek \cite{Judish1999},
% 	\item doktorská práce \cite{Valente2005},
% 	\item technická zpráva \cite{Fralick1997},
% 	\item webová stránka \cite{WWWCST}.
% \end{itemize}